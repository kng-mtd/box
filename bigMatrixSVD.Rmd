---
title: "SVD, PCA for bigMatrix"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# **å·¨å¤§CSVãƒ‡ãƒ¼ã‚¿ã‚’Rã§ç‰¹ç•°å€¤åˆ†è§£ï¼ˆSVDï¼‰ãƒ»ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰**

#å¯†è¡Œåˆ—å½¢å¼ã¨ç–è¡Œåˆ—å½¢å¼ã®æ¯”è¼ƒ
```{r}
library(Matrix)

n=20
r=20
c=10
i=sample(1:r,n,replace=T)
j=sample(1:c,n,replace=T)
tb=tibble(i=i,j=j) |> unique()
n0=nrow(tb)
x=runif(n0,0,1)
bind_cols(tb,x=x)

mx=matrix(0,nrow=r,ncol=c)
for(k in 1:n0) mx[tb$i[k],tb$j[k]]=x[k]
mx
object.size(mx)


spmx=sparseMatrix(i=tb$i,j=tb$j,x=x)
spmx
summary(spmx)
object.size(spmx)

summary(mx-spmx)


library(rsvd)

n=100
m=50
density=0.1

spmx=rsparsematrix(n,m,density)*10
print(spmx)
summary(spmx)

k=30

sv=rsvd(spmx, k)
print(sv)

amx=sv$u %*% diag(sv$d) %*% t(sv$v)

print(amx)

Matrix(amx,sparse=T) |> summary()


heatmap(as.matrix(spmx),Rowv=NA,Colv=NA,scale='none',margins=c(3,3),main='origin')
heatmap(amx,Rowv=NA,Colv=NA,scale='none',margins=c(3,3),main='approx')



n=1e6
r=1e4
c=1e3
i=sample(1:r,n,replace=T)
j=sample(1:c,n,replace=T)
x=runif(n,0,1)

spmx=sparseMatrix(i=i,j=j,x=x)
object.size(spmx)

k=30

system.time({
  sv=rsvd(spmx, k)
})
summary(sv)
object.size(sv)




library(RSpectra)
library(rsvd)

A=rsparsematrix(r,c, density = 0.1)

system.time({
  svd_rspectra=svds(A, k = k)
})

system.time({
  svd_rsvd=rsvd(A, k = k)
})

```




å·¨å¤§ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¡Œã€åˆ—ã€å€¤ã®å½¢å¼ï¼‰ã‚’ä½œæˆã™ã‚‹
```{r}
library(data.table)

#file.remove(file)
file='big_sparse_mat.csv'

n=1e8 # element not 0
r=1e4
c=1e4
batch=1e6  # batch size
```

```{r}
for (i in seq(1, n, by = batch)) {
  row=sample(1:r, size = batch, replace = T)
  col=sample(1:c, size = batch, replace = T)
  val=runif(batch, min = -1, max = 1)
  df=data.table(row = row, col = col, val = val)
  
  fwrite(df, file, quote = FALSE, sep = ",", row.names = FALSE, append = TRUE)
}
rm(df)
```





## **ç–è¡Œåˆ—ï¼ˆSparse Matrixï¼‰ã®å ´åˆ**

```{r}
library(Matrix)
library(RSpectra)
library(irlba)
gc()

df=fread(file)  # "row,col,value" å½¢å¼
spmx <- sparseMatrix(i = df$row, j = df$col, x = df$val)

# å›ºæœ‰å€¤åˆ†è§£
system.time({
  evd <- eigs(spmx, k = 20)
})

evd$values  # å›ºæœ‰å€¤
evd$vectors[1:5,] # å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«


system.time({
  svd<-irlba(spmx,20)
})

svd$d  # ç‰¹ç•°å€¤ï¼ˆâˆšå›ºæœ‰å€¤ã€å…ƒã®è¡Œåˆ—ãŒå…±åˆ†æ•£è¡Œåˆ—ã®ã¨ãã¯ä¸»æˆåˆ†ã®åˆ†æ•£ï¼‰
svd$u[1:5,]  # å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå¯¾è±¡ã®kæ¬¡å…ƒç‰¹å¾´é‡ï¼‰
svd$v[1:5,]  # å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå…ƒã®è¡Œåˆ—ãŒå…±åˆ†æ•£è¡Œåˆ—ã®ã¨ãã¯ä¸»æˆåˆ†è² è·é‡ï¼‰
```


```{r}
library(Matrix)
library(irlba)

gc()
file='big_sparse_mat.csv'
df=fread(file)  # "row,col,value" å½¢å¼
sparse_mat=sparseMatrix(i = df$row, j = df$col, x = df$val)
rm(df)

# è¿‘ä¼¼ SVD
system.time({
  svd=irlba(sparse_mat, nu = 20, nv = 20)
})

# ä¸»æˆåˆ†å¾—ç‚¹
pca_scores=svd$u %*% diag(svd$d)
```


```{r}
library(Matrix)
library(RSpectra)

gc()
df=fread(file)  # "row,col,value" å½¢å¼
sparse_mat=sparseMatrix(i = df$row, j = df$col, x = df$val)
rm(df)

# è¿‘ä¼¼SVD
system.time({
  svd=svds(sparse_mat, k = 20)
})

# ä¸»æˆåˆ†å¾—ç‚¹
pca_scores=svd$u %*% diag(svd$d)
```


```{r}
library(Matrix)
library(rsvd)

gc()
df=fread(file)  # "row,col,value" å½¢å¼
sparse_mat=sparseMatrix(i = df$row, j = df$col, x = df$val)
rm(df)

# è¿‘ä¼¼SVD
system.time({
  svd=rsvd(sparse_mat, k = 20)
})

# ä¸»æˆåˆ†å¾—ç‚¹
pca_scores=svd$u %*% diag(svd$d)
```




#ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ã®è¡Œåˆ—ã‚’ç‰¹ç•°å€¤åˆ†è§£

å¯†è¡Œåˆ—ã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸Šã§æ­£è¦åŒ–ã€é©å½“ãªå®šæ•°å€ã‚’ã—ã¦ä¸¸ã‚ãŸã‚‚ã®ã‚’æ•´æ•°å‹ã¨ã—ã¦ã‹ã‚‰ã€è¨ˆç®—å¯¾è±¡ã®matrixã‚’ã¤ãã‚‹ã“ã¨ã§è¡Œåˆ—ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚µã‚¤ã‚ºã‚’1/2ã«ã™ã‚‹
```{r}
library(rsvd)

gc()
k=4e4
mx=matrix(as.integer(round(runif(k**2,-1,1)*100)),k,k)

object.size(mx)

# è¿‘ä¼¼SVD
system.time({
  svd=rsvd(mx, k = 20)
})

# ä¸»æˆåˆ†å¾—ç‚¹
pca_scores=svd$u %*% diag(svd$d)

```




```{r}
library(ff)
library(bigstatsr)
library(Matrix)
library(tidyverse)
gc()

csv_file <- "big_sparse_mat.csv"

# ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã™ã‚‹å¤‰æ•°
row_id <- c()
col_id <- c()
vals <- c()

# ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†ã™ã‚‹é–¢æ•°
callback <- function(chunk, pos) {
  # ã‚«ãƒ©ãƒ åã‚’å¼·åˆ¶è¨­å®š
  chunk <- setNames(chunk, c("row", "col", "val"))
  
  # NA ã‚’å‰Šé™¤
  #chunk <- chunk |> drop_na(row, col, val)
  
  # æ•´æ•°å‹ã«å¤‰æ›
  chunk$row <- as.integer(chunk$row)
  chunk$col <- as.integer(chunk$col)
  chunk$val <- as.numeric(chunk$val)
  
  # ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©
  row_id <<- c(row_id, chunk$row)
  col_id <<- c(col_id, chunk$col)
  vals <<- c(vals, chunk$val)
}

# CSV ã‚’ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†
chunk_size <- 1e6
read_csv_chunked(
  file = csv_file, 
  callback = SideEffectChunkCallback$new(callback), 
  chunk_size = chunk_size, 
  col_names = T  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è‡ªå‹•èªè­˜
)


# æ—¢å­˜ã®ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
file.remove("big_matrix.fbm")
file.remove("big_matrix.fbm.bk")

# FBMï¼ˆFile-backed Big Matrixï¼‰ã‚’ä½œæˆ
fbm <- FBM(max(row_id), max(col_id), backingfile = "big_matrix.fbm")

# FBMã®è¡Œåˆ—ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ï¼ˆsparseMatrixã§ã¯ãªãã€FBMã®å†…éƒ¨ã«æ ¼ç´ã™ã‚‹ï¼‰
for (i in seq_along(vals)) {
  fbm[row_id[i], col_id[i]] <- vals[i]
}

# SVD ã‚’å®Ÿè¡Œ
svd <- big_randomSVD(fbm, k = 10)


svd$d  # ç‰¹ç•°å€¤ï¼ˆâˆšå›ºæœ‰å€¤ã€å…ƒã®è¡Œåˆ—ãŒå…±åˆ†æ•£è¡Œåˆ—ã®ã¨ãã¯ä¸»æˆåˆ†ã®åˆ†æ•£ï¼‰
svd$u[1:5,]  # å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå¯¾è±¡ã®kæ¬¡å…ƒç‰¹å¾´é‡ï¼‰
svd$v[1:5,]  # å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå…ƒã®è¡Œåˆ—ãŒå…±åˆ†æ•£è¡Œåˆ—ã®ã¨ãã¯ä¸»æˆåˆ†è² è·é‡ï¼‰

saveRDS(svd,'svd_result.rds')
```




`fbpca` ã‚’ä½¿ã£ã¦ **ãƒ©ãƒ³ãƒ€ãƒ åŒ– SVD** ã‚’é©ç”¨ã™ã‚‹ Python ã‚³ãƒ¼ãƒ‰ã‚’ç¤ºã—ã¾ã™ã€‚  
ã“ã®æ‰‹æ³•ã¯ã€é€šå¸¸ã® SVD ã‚ˆã‚Šã‚‚è¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ãã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«ã‚‚é©ã—ã¦ã„ã¾ã™ã€‚

---

### **1. `fbpca` ã‚’ä½¿ã£ãŸãƒ©ãƒ³ãƒ€ãƒ åŒ– SVD**
```sh
curl -o miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash miniconda.sh
conda --version

conda update conda

conda create -n env0
conda env list
conda activate env0
conda clean --all

conda install pandas numpy scipy fbpca
#or
conda install -c conda-forge fbpca
#or
pip install fbpca

conda list

python3 bigmat_fbpca.py

conda deactivate
conda remove env0 --all
```

bigmat_fbpca.py
```python
import pandas as pd
import numpy as np
from scipy.sparse import coo_matrix
from scipy.sparse.linalg import svds

# Read CSV file in chunks
csv_file = "big_sparse_mat.csv"
chunk_size = 10**5

row_list, col_list, val_list = [], [], []

for chunk in pd.read_csv(csv_file, chunksize=chunk_size, names=["row", "col", "val"], header=0):
    chunk.dropna(subset=["row", "col", "val"], inplace=True)  # Remove NA values
    row_list.append(chunk["row"].to_numpy(dtype=int))
    col_list.append(chunk["col"].to_numpy(dtype=int))
    val_list.append(chunk["val"].to_numpy(dtype=float))

# Concatenate lists into NumPy arrays (improves performance)
row_ids = np.concatenate(row_list)
col_ids = np.concatenate(col_list)
values = np.concatenate(val_list)

# Determine matrix size (get max indices)
n_rows, n_cols = row_ids.max() + 1, col_ids.max() + 1

# Create sparse matrix (COO format)
sparse_matrix = coo_matrix((values, (row_ids, col_ids)), shape=(n_rows, n_cols))

# Perform sparse SVD (k=10, memory-efficient)
U, S, Vt = svds(sparse_matrix, k=10)

# Display results
print("Singular values:", S)
print("Left singular vectors (first 5 rows):\n", U[:5, :])
print("Right singular vectors (first 5 columns):\n", Vt

```

---

### **2. `fbpca.pca()` ã®ä»•çµ„ã¿**
`fbpca` ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ãŸ SVD ã‚’å®Ÿè¡Œã—ã€  
å¾“æ¥ã®å³å¯†ãª SVD ã‚ˆã‚Š **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ãã€é«˜é€Ÿ** ã§ã™ã€‚

âœ… **ãƒ¡ãƒªãƒƒãƒˆ**
- **é€šå¸¸ã® SVD ã‚ˆã‚Šã‚‚é€Ÿã„**ï¼ˆãƒ©ãƒ³ãƒ€ãƒ åŒ–ã«ã‚ˆã‚Šè¨ˆç®—é‡ã‚’å‰Šæ¸›ï¼‰
- **ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã«å¯¾å¿œ**
- **ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã‚’æŠ‘ãˆã‚‰ã‚Œã‚‹**


---




é€æ¬¡çš„PCAï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³PCAï¼‰ã‚„é€æ¬¡çš„SVDï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³SVDï¼‰ã‚’Rã§è¡Œã†æ–¹æ³•ã¯ã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚ä¸€èˆ¬çš„ãªæ–¹æ³•ã¨ã—ã¦ã€ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã™ã€‚

### 1. **é€æ¬¡çš„PCAï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³PCAï¼‰**
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³PCAã¯ãƒ‡ãƒ¼ã‚¿ãŒé€æ¬¡çš„ã«ä¸ãˆã‚‰ã‚Œã‚‹å ´åˆã§ã‚‚ä¸»æˆåˆ†åˆ†æã‚’æ›´æ–°ã§ãã‚‹æ–¹æ³•ã§ã™ã€‚Rã§ã¯ `onlinePCA` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒä¾¿åˆ©ã§ã™ã€‚

#### **æ–¹æ³•1: `onlinePCA` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã†**

https://cran.r-universe.dev/onlinePCA
https://www.academia.edu/9900402/R_package_onlinePCA_Online_Principal_Component_Analysis


batchpca	Batch PCA
bsoipca	Block Stochastic Orthononal Iteration (BSOI)
ccipca	Candid Covariance-Free Incremental PCA
ghapca	Generalized Hebbian Algorithm for PCA
impute	BLUP Imputation of Missing Values
incRpca	Incremental PCA
incRpca.block	Incremental PCA with Block Update
incRpca.rc	Incremental PCA With Reduced Complexity
perturbationRpca	Recursive PCA using a rank 1 perturbation method
secularRpca	Recursive PCA Using Secular Equations
sgapca	Stochastic Gradient Ascent PCA
snlpca	Subspace Network Learning PCA




ã“ã‚Œã‚‰ã¯ã€é€æ¬¡çš„ã¾ãŸã¯ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ãª PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰ã®ç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„æ‰‹æ³•ã§ã™ã€‚ãã‚Œãã‚Œã«ã¤ã„ã¦ç°¡å˜ã«èª¬æ˜ã—ã¾ã™ã€‚

### 1. **Recursive PCA using a rank 1 perturbation method**
   - ã“ã®æ–¹æ³•ã§ã¯ã€PCAã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã«ã€è¡Œåˆ—ã®ãƒ©ãƒ³ã‚¯1ã®æ‘‚å‹•ï¼ˆå¤‰åŒ–ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒä¸ãˆã‚‰ã‚Œã‚‹ãŸã³ã«ã€ãƒ©ãƒ³ã‚¯1ã®æ›´æ–°ã‚’åŠ ãˆã¦PCAã®ä¸»æˆåˆ†ã‚’å†è¨ˆç®—ã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã¯ã€ä¸»æˆåˆ†ã‚’åŠ¹ç‡çš„ã«æ›´æ–°ã™ã‚‹ã“ã¨ãŒã§ãã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ãŒå°‘ãªãã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã«é©ã—ã¦ã„ã¾ã™ã€‚

### 2. **Recursive PCA Using Secular Equations**
   - ã“ã®æ–¹æ³•ã¯ã€é€æ¬¡çš„ãªPCAã‚’è¡Œã†ãŸã‚ã«ã€Œä¸–ä¿—æ–¹ç¨‹å¼ï¼ˆSecular Equationsï¼‰ã€ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ä¸–ä¿—æ–¹ç¨‹å¼ã¯ã€è¡Œåˆ—ã®å›ºæœ‰å€¤ã¨å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†è¨ˆç®—ã™ã‚‹ãŸã‚ã®æ–¹ç¨‹å¼ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãŒé€æ¬¡çš„ã«è¿½åŠ ã•ã‚Œã‚‹ãŸã³ã«PCAã®æ›´æ–°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥å‰ã®è¨ˆç®—çµæœã‚’ä¿å­˜ã—ã¤ã¤ã€åŠ¹ç‡çš„ã«æ›´æ–°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚

### 3. **Incremental PCA**
   - ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã¯ã€é€šå¸¸ã®PCAã¨ç•°ãªã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ã™ã¹ã¦å‡¦ç†ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒã”ã¨ã«å‡¦ç†ã—ã¾ã™ã€‚ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒéå¸¸ã«å¤§ãã„å ´åˆã‚„ãƒ¡ãƒ¢ãƒªã«åã¾ã‚Šãã‚‰ãªã„å ´åˆã«ä¾¿åˆ©ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®å„ãƒãƒƒãƒã”ã¨ã«PCAã‚’æ›´æ–°ã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¯€ç´„ã—ã¾ã™ã€‚

### 4. **Incremental PCA with Block Update**
   - ãƒ–ãƒ­ãƒƒã‚¯æ›´æ–°ã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†ã‘ã¦å‡¦ç†ã—ã¾ã™ã€‚å„ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«PCAã‚’æ›´æ–°ã—ã€å…¨ä½“ã®æ›´æ–°ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã¾ã™ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã‚’ã‚ˆã‚Šå¤§ããªãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§è¡Œã†ãŸã‚ã€è¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

### 5. **Incremental PCA With Reduced Complexity**
   - è¤‡é›‘æ€§ã‚’å‰Šæ¸›ã—ãŸã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã¯ã€é€šå¸¸ã®ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã‚ˆã‚Šã‚‚è¨ˆç®—é‡ã‚’æ¸›ã‚‰ã™ã“ã¨ã‚’ç›®æŒ‡ã—ãŸæ‰‹æ³•ã§ã™ã€‚ç‰¹ã«é«˜æ¬¡å…ƒã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€è¨ˆç®—ã®åŠ¹ç‡åŒ–ã‚’å›³ã‚‹ãŸã‚ã®æ–¹æ³•ãŒå«ã¾ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚ˆã‚Šå°‘ãªãã—ã¦PCAã‚’æ›´æ–°ã§ãã¾ã™ã€‚

### 6. **Block Stochastic Orthogonal Iteration (BSOI)**
   - BSOIã¯ã€ç¢ºç‡çš„ãªãƒ–ãƒ­ãƒƒã‚¯æ›´æ–°ã‚’ç”¨ã„ã¦PCAã‚’è¨ˆç®—ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§åˆ†å‰²ã—ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã®ä¸»æˆåˆ†ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã¯ã€ç‰¹ã«å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦åŠ¹æœçš„ã§ã‚ã‚Šã€ç¢ºç‡çš„ãªæ‰‹æ³•ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã®ç²¾åº¦ã‚’ä¿ã¡ãªãŒã‚‰åŠ¹ç‡çš„ã«ä¸»æˆåˆ†ã‚’æ±‚ã‚ã¾ã™ã€‚

### 7. **Candid Covariance-Free Incremental PCA**
   - ã“ã®æ–¹æ³•ã¯ã€å…±åˆ†æ•£è¡Œåˆ—ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ãªãã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã‚’å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã§ã™ã€‚å…±åˆ†æ•£è¡Œåˆ—ã®è¨ˆç®—ã‚’çœç•¥ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã‚’å°‘ãªãã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®æ–¹æ³•ã¯ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã‚‚é©ç”¨å¯èƒ½ã§ã™ã€‚

### 8. **Generalized Hebbian Algorithm for PCA**
   - ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€PCAã‚’æ±‚ã‚ã‚‹ãŸã‚ã®é€æ¬¡çš„ãªå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚Šã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ˜ãƒ–å­¦ç¿’æ³•ã‚’åŸºã«ã—ã¦ã„ã¾ã™ã€‚ä¸»æˆåˆ†ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ¼ã‚¿ã®è‡ªå·±çµ„ç¹”åŒ–ã‚’åˆ©ç”¨ã—ã¦æ›´æ–°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®è‡ªå·±çµ„ç¹”åŒ–ã‚’åˆ©ç”¨ã—ã¦åŠ¹ç‡çš„ã«PCAã‚’æ›´æ–°ã—ã¾ã™ã€‚

### 9. **Stochastic Gradient Ascent PCA**
   - ç¢ºç‡çš„å‹¾é…ä¸Šæ˜‡æ³•ã‚’ä½¿ç”¨ã—ã¦PCAã‚’æ±‚ã‚ã‚‹æ‰‹æ³•ã§ã™ã€‚é€šå¸¸ã€PCAã®è¨ˆç®—ã«ã¯å›ºæœ‰å€¤åˆ†è§£ãŒå¿…è¦ã§ã™ãŒã€ã“ã®æ‰‹æ³•ã§ã¯å‹¾é…ä¸Šæ˜‡æ³•ã‚’ä½¿ã£ã¦é€æ¬¡çš„ã«ä¸»æˆåˆ†ã‚’æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç¢ºç‡çš„ãªæ›´æ–°ã‚’ç”¨ã„ã‚‹ãŸã‚ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚é©å¿œã§ãã‚‹ã®ãŒç‰¹å¾´ã§ã™ã€‚

### 10. **Subspace Network Learning PCA**
   - ã‚µãƒ–ã‚¹ãƒšãƒ¼ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å­¦ç¿’ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ã„ãŸPCAã®å­¦ç¿’æ³•ã§ã™ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã®ä½æ¬¡å…ƒè¡¨ç¾ã‚’å­¦ç¿’ã—ã€ä¸»æˆåˆ†ã‚’é€æ¬¡çš„ã«æ›´æ–°ã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®éç·šå½¢æ€§ã‚’æ‰±ã†ã“ã¨ãŒã§ãã‚‹ãŸã‚ã€PCAã®ç·šå½¢æ€§ã‚’æ‹¡å¼µã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### 11. **BLUP Imputation of Missing Values**
   - BLUPï¼ˆBest Linear Unbiased Predictionï¼‰æ³•ã‚’ç”¨ã„ã¦ã€æ¬ æå€¤ã‚’è£œå®Œã™ã‚‹æ‰‹æ³•ã§ã™ã€‚PCAã®ã‚ˆã†ãªç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€æ¬ æã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’äºˆæ¸¬ã—è£œå®Œã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬ æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã§ã‚‚PCAã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

### 12. **Batch PCA**
   - ãƒãƒƒãƒPCAã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ã™ã¹ã¦å‡¦ç†ã™ã‚‹é€šå¸¸ã®PCAã®æ–¹æ³•ã§ã™ã€‚ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã¨ã¯ç•°ãªã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§å‡¦ç†ã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦åŠ¹ç‡çš„ã«ä¸»æˆåˆ†ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€æœ€ã‚‚æ­£ç¢ºãªçµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨è¨ˆç®—è³‡æºã‚’å¤§é‡ã«æ¶ˆè²»ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

ã“ã‚Œã‚‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„æ‰‹æ³•ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ã‚„è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ãŒã§ãã€é€æ¬¡çš„ãªãƒ‡ãƒ¼ã‚¿è§£æã‚„å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹PCAã®è¨ˆç®—ã‚’åŠ¹ç‡çš„ã«è¡Œã†ãŸã‚ã«å½¹ç«‹ã¡ã¾ã™ã€‚


ã“ã‚Œã‚‰ã®PCAã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸­ã§ã€Œé«˜é€Ÿãªé †åºã€ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œé€Ÿåº¦ã¨è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡æ€§ã«ä¾å­˜ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€é«˜é€Ÿãªé †åºã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã©ã‚Œã ã‘åŠ¹ç‡çš„ã«è¨ˆç®—ã§ãã‚‹ã‹ã€ãƒ¡ãƒ¢ãƒªã‚’ã©ã‚Œã ã‘ç¯€ç´„ã§ãã‚‹ã‹ã€ãã—ã¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã©ã‚Œã ã‘ã‚·ãƒ³ãƒ—ãƒ«ã«å®Ÿè¡Œã§ãã‚‹ã‹ã«é–¢ä¿‚ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã«ã€é«˜é€Ÿãªé †åºã‚’ç¤ºã™ãŸã‚ã«ã€å„æ‰‹æ³•ã‚’ç°¡å˜ã«è©•ä¾¡ã—ã¾ã™ã€‚

### é«˜é€Ÿãªé †åºï¼ˆä¸Šä½ï¼‰ï¼š
1. **Incremental PCA**
   - ãƒãƒƒãƒã”ã¨ã«é€æ¬¡çš„ã«è¨ˆç®—ã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ãŒå°‘ãªãã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦é«˜é€Ÿã§ã™ã€‚ç‰¹ã«è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã«æœ‰åŠ¹ã§ã™ã€‚
   
2. **Incremental PCA with Block Update**
   - ã€Œã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«PCAã€ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’å¤§ããªãƒ–ãƒ­ãƒƒã‚¯ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—åŠ¹ç‡ãŒã•ã‚‰ã«å‘ä¸Šã—ã¾ã™ã€‚ç‰¹ã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ‰åˆ©ã§ã™ã€‚

3. **Candid Covariance-Free Incremental PCA**
   - å…±åˆ†æ•£è¡Œåˆ—ã‚’è¨ˆç®—ã›ãšã«é€æ¬¡çš„ã«PCAã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã€è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ã€ãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚‚æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã€é«˜é€Ÿã§ã™ã€‚

4. **Block Stochastic Orthogonal Iteration (BSOI)**
   - ç¢ºç‡çš„ãªãƒ–ãƒ­ãƒƒã‚¯æ›´æ–°ã‚’ç”¨ã„ã‚‹ãŸã‚ã€åŠ¹ç‡çš„ã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾å¿œã§ãã€é«˜é€Ÿã«ä¸»æˆåˆ†ã‚’æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### ä¸­ç¨‹åº¦ã®é †åºï¼š
5. **Recursive PCA using a rank 1 perturbation method**
   - ãƒ©ãƒ³ã‚¯1ã®æ‘‚å‹•ã‚’ç”¨ã„ã‚‹ãŸã‚ã€é€æ¬¡çš„ãªPCAæ›´æ–°ã¯æ¯”è¼ƒçš„é«˜é€Ÿã§ã™ãŒã€æ›´æ–°æ–¹æ³•ã‚„çŠ¶æ³ã«å¿œã˜ã¦ä»–ã®æ‰‹æ³•ã«é…ã‚Œã‚’å–ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚

6. **Recursive PCA Using Secular Equations**
   - ä¸–ä¿—æ–¹ç¨‹å¼ã‚’ç”¨ã„ãŸé€æ¬¡æ›´æ–°ã¯ã€æ¯”è¼ƒçš„è¨ˆç®—ãŒè¤‡é›‘ã§ã‚ã‚Šã€åŠ¹ç‡æ€§ã«æ¬ ã‘ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€ãƒ¡ãƒ¢ãƒªã®æ¶ˆè²»ã‚’æŠ‘ãˆãªãŒã‚‰ç²¾åº¦ã‚’ä¿ã¤ã“ã¨ãŒã§ãã¾ã™ã€‚

7. **Stochastic Gradient Ascent PCA**
   - ç¢ºç‡çš„å‹¾é…ä¸Šæ˜‡æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚’é€æ¬¡çš„ã«è¡Œã„ã¾ã™ãŒã€åæŸé€Ÿåº¦ãŒé…ã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€é«˜é€Ÿã§ã¯ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

### ã‚ˆã‚Šé…ã„é †åºï¼ˆä¸€èˆ¬çš„ã«è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒå¤šãå¿…è¦ï¼‰ï¼š
8. **Generalized Hebbian Algorithm for PCA**
   - ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ãã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯é€šå¸¸ã€è¨ˆç®—ãŒé…ããªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ç‰¹ã«ã€æ›´æ–°ãŒåå¾©çš„ã§ã‚ã‚‹ãŸã‚ã€é«˜é€Ÿã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚

9. **Subspace Network Learning PCA**
   - ã‚µãƒ–ã‚¹ãƒšãƒ¼ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’ã¯ã€éç·šå½¢æ€§ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«è¤‡é›‘ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€è¨ˆç®—ãŒé…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

10. **BLUP Imputation of Missing Values**
    - æ¬ æå€¤è£œå®Œã‚’è¡Œã†å ´åˆã€BLUPæ³•ã¯ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦è¨ˆç®—é‡ãŒå¤šãã€é…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ¬ æå€¤è£œå®Œã®ãŸã‚ã«ã¯è¿½åŠ ã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦ã§ã™ã€‚

11. **Batch PCA**
    - ãƒãƒƒãƒPCAã¯ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ã™ã¹ã¦å‡¦ç†ã™ã‚‹ãŸã‚ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—è³‡æºã‚’å¤§é‡ã«æ¶ˆè²»ã—ã¾ã™ã€‚ãã®ãŸã‚ã€é«˜é€Ÿã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚



```{r}
library(onlinePCA)

n=1e4
d=100
q=10

x=matrix(rnorm(n*d,1,2),n,d)

# conventional strict PCA from data matrix with prcomp
system.time({pca0=prcomp(x,scale.=T)})

pca0$sdev[1:q]^2
pca0$rotation[1:5,1:q]

# conventional strict PCA from correlation matrix matrix with eigen
system.time({pca1=eigen(cor(x))})

pca1$values[1:q]
pca1$vectors[1:5,1:q]

# approximated PCA from data matrix with batch PCA
system.time({pca2=batchpca(scale(x,scale=T),q,byrow=T)})

pca2$values
pca2$vectors[1:5,1:q]

# approximated PCA from correlation matrix with batch PCA
system.time({pca3=batchpca(cor(x),q,type='covariance')})

pca3$values
pca3$vectors[1:5,1:q]



# Incremental PCA (IPCA, centered), add one by one row
x0=scale(x)
n1=5e3 #initial rows

pca=prcomp(x0[1:n1,])
m=pca$center
pca=list(values=pca$sdev[1:q]^2, vectors=pca$rotation[,1:q])

for(i in (n1+1):n){
  m=updateMean(m,x0[i,],i-1)
  pca=incRpca(pca$values, pca$vectors, x0[i,], i-1, q=q, center=m)
}

pca$values
pca$vectors[1:5,1:q]
```


```{r}
tb0=penguins |>
  drop_na() |>
  mutate(year=as.factor(year))

tb=model.matrix(~.,tb0)[,-1]

q=5

pca0=prcomp(tb,scale.=T)
pca0$sdev[1:q]^2
pca0$rotation[,1:q]

pca1=eigen(cor(tb))
pca1$values
pca1$vectors[1:5,1:q]

pca2=batchpca(scale(tb,scale=T),q,byrow=T)
pca2$values
pca2$vectors[,1:q]

pca3=batchpca(cor(tb),q,type='covariance')
pca3$values
pca3$vectors[1:5,1:q]


tb0=scale(tb)
n=nrow(tb0)
n1=200 #initial rows

pca=prcomp(tb0[1:n1,])
m=pca$center
pca=list(values=pca$sdev[1:q]^2, vectors=pca$rotation[,1:q])

for(i in (n1+1):n){
  m=updateMean(m,tb0[i,],i-1)
  pca=incRpca(pca$values, pca$vectors, tb0[i,], i-1, q=q, center=m)
}

pca$values
pca$vectors[,1:q]
```



---

### 2. **é€æ¬¡çš„SVDï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³SVDï¼‰**
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³SVDã¯ç‰¹ã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æœ‰åŠ¹ã§ã™ã€‚Rã§ã¯ `irlba` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚„ `softImpute` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒåˆ©ç”¨ã§ãã¾ã™ã€‚

#### **æ–¹æ³•1: `irlba` ã‚’ä½¿ã†**
`irlba` ã¯ç‰¹ç•°å€¤åˆ†è§£ï¼ˆSVDï¼‰ã®è¿‘ä¼¼è¨ˆç®—ã‚’æä¾›ã—ã¾ã™ã€‚
#### **ã‚¹ãƒ†ãƒƒãƒ—1: åˆæœŸãƒ‡ãƒ¼ã‚¿ã§SVDã‚’è¨ˆç®—**
```r
install.packages("irlba")
library(irlba)

# åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆè¡Œåˆ—ï¼‰
set.seed(123)
X <- matrix(rnorm(100 * 10), nrow=100, ncol=10)  # 100è¡Œ10åˆ—ã®ãƒ‡ãƒ¼ã‚¿

# SVDã®åˆæœŸè¨ˆç®— (ä¸Šä½3ã¤ã®ç‰¹ç•°å€¤ãƒ»ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«)
k <- 3
svd_result <- irlba(X, nv=k)

# åˆæœŸã®å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã€ç‰¹ç•°å€¤ã€å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«
U <- svd_result$u
D <- diag(svd_result$d)
V <- svd_result$v
```
#### **ã‚¹ãƒ†ãƒƒãƒ—2: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãªãŒã‚‰SVDã‚’æ›´æ–°**
```r
# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒ­ãƒƒã‚¯ (10è¡Œ10åˆ—)
new_data <- matrix(rnorm(10 * 10), nrow=10, ncol=10)

# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ã«è¿½åŠ 
X_new <- rbind(X, new_data)

# å†è¨ˆç®—ï¼ˆå…¨ä½“ã‚’å†è¨ˆç®—ã™ã‚‹æ–¹æ³•ï¼‰
svd_result <- irlba(X_new, nv=k)

# æ›´æ–°å¾Œã®å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã€ç‰¹ç•°å€¤ã€å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«
U_new <- svd_result$u
D_new <- diag(svd_result$d)
V_new <- svd_result$v
```


#### **æ–¹æ³•2: `softImpute` ã‚’ä½¿ã†**
è¡Œåˆ—ã®æ¬ æå€¤è£œå®Œå‘ã‘ã§ã™ãŒã€é€æ¬¡çš„ãªSVDã«ã‚‚ä½¿ãˆã¾ã™ã€‚
```r
install.packages("softImpute")
library(softImpute)

# åˆæœŸãƒ‡ãƒ¼ã‚¿
X <- matrix(rnorm(100 * 10), nrow=100, ncol=10)

# åˆæœŸã®SVDï¼ˆãƒ©ãƒ³ã‚¯3ã¾ã§ã®è¿‘ä¼¼ï¼‰
svd_result <- softImpute(X, rank.max=3, lambda=0)

# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ï¼ˆè¿½åŠ ï¼‰
new_data <- matrix(rnorm(10 * 10), nrow=10, ncol=10)
X_new <- rbind(X, new_data)

# ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã‚’ç¶­æŒã—ã¤ã¤å†è¨ˆç®—
svd_result_new <- softImpute(X_new, rank.max=3, lambda=0)
```





## **ğŸ”¹ é€æ¬¡çš„ï¼ˆã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ï¼‰rSVD ã®è€ƒãˆæ–¹**
é€šå¸¸ã® `rsvd()` ã¯ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ä¸€æ‹¬å‡¦ç†ã™ã‚‹ã®ã§ã€**æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ãŸã³ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®—ã—ç›´ã™å¿…è¦ãŒã‚ã‚Šã¾ã™**ã€‚  
ã—ã‹ã—ã€ä»¥ä¸‹ã®æ‰‹æ³•ã‚’ç”¨ã„ã‚Œã°ã€**å°‘ãªã„è¨ˆç®—é‡ã§SVDã‚’æ›´æ–°** ã§ãã¾ã™ã€‚

---

### **æ–¹æ³•1: è¿‘ä¼¼çš„ã«rSVDã‚’æ›´æ–°**

```r
library(rsvd)

update_rsvd <- function(rsvd_result, new_data, k=50) {
  # æ—¢å­˜ã®ç‰¹ç•°å€¤åˆ†è§£çµæœ
  U_old <- rsvd_result$u
  D_old <- diag(rsvd_result$d)
  V_old <- rsvd_result$v
  
  # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’è¿‘ä¼¼å†æ§‹ç¯‰
  X_approx <- U_old %*% D_old
  
  # æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
  X_updated <- rbind(X_approx, new_data)
  
  # å†ã³rSVDã‚’é©ç”¨
  new_rsvd_result <- rsvd(X_updated, k=k)
  
  return(new_rsvd_result)
}

# ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‡ãƒ¼ã‚¿è¡Œåˆ—
set.seed(123)
X <- matrix(rnorm(1000 * 500), nrow=1000, ncol=500)

# åˆå›ã®rSVD
rsvd_result <- rsvd(X, k=50)

# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ 
new_data <- matrix(rnorm(100 * 500), nrow=100, ncol=500)
rsvd_result <- update_rsvd(rsvd_result, new_data, k=50)
```

1. æ—¢å­˜ã®SVD (`U D V^T`) ã§è¿‘ä¼¼è¡Œåˆ— `X_approx` ã‚’ä½œæˆã€‚
2. ãã“ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ `new_data` ã‚’çµåˆ (`rbind`)ã€‚
3. æ–°ã—ã„ `X_updated` ã«å¯¾ã—ã¦ `rsvd()` ã‚’é©ç”¨ã—ã€æ–°ã—ã„SVDã‚’å–å¾—ã€‚

å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã›ãšã€ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã‚’æ´»ç”¨ã—ã¦åŠ¹ç‡çš„ã«æ›´æ–°  
å®Œå…¨ãªSVDã®å†è¨ˆç®—ã‚ˆã‚Šã‚‚é€Ÿã„  
å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä½¿ã„ã‚„ã™ã„  

---

### **æ–¹æ³•2: `irlba()` ã‚’ç”¨ã„ãŸé€æ¬¡çš„SVD**
ã‚‚ã— `rsvd` ã§ã¯ãªã **`irlba`** ã‚’ä½¿ã†å ´åˆã€ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„ **é€æ¬¡SVDï¼ˆIncremental SVDï¼‰** ã®è¨ˆç®—ãŒå¯èƒ½ã§ã™ã€‚

```r
library(irlba)

update_irlba <- function(irlba_result, new_data, k=50) {
  # æ—¢å­˜ã®ç‰¹ç•°å€¤åˆ†è§£çµæœ
  U_old <- irlba_result$u
  D_old <- diag(irlba_result$d)
  V_old <- irlba_result$v
  
  # è¿‘ä¼¼å†æ§‹ç¯‰
  X_approx <- U_old %*% D_old
  
  # æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
  X_updated <- rbind(X_approx, new_data)
  
  # å†ã³SVDã‚’é©ç”¨
  new_irlba_result <- irlba(X_updated, nv=k)
  
  return(new_irlba_result)
}

# åˆå›ã®SVD
irlba_result <- irlba(X, nv=50)

# æ–°ãƒ‡ãƒ¼ã‚¿ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ 
irlba_result <- update_irlba(irlba_result, new_data, k=50)
```
`irlba` ã¯ `rsvd` ã‚ˆã‚Šã‚‚å³å¯†ãªä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ã‚’æ±‚ã‚ã‚‹ã®ã«å‘ã„ã¦ã„ã¾ã™ã€‚





Ubuntuä¸Šã®Rã§ **rSVDï¼ˆãƒ©ãƒ³ãƒ€ãƒ åŒ–ç‰¹ç•°å€¤åˆ†è§£ï¼‰** ã®è¨ˆç®—ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®æ–¹æ³•ã€‚  
BLASã®ä¸¦åˆ—åŒ–ã‚„OpenMPã®æœ€é©åŒ–ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚’å¤§å¹…ã«é«˜é€ŸåŒ–ã€‚

---

## **1. BLASï¼ˆOpenBLAS / MKLï¼‰ã®ä¸¦åˆ—åŒ–**
Rã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆBLASã¯ä¸¦åˆ—åŒ–ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€**ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰å¯¾å¿œã®BLASã‚’ä½¿ç”¨** ã™ã‚‹ã“ã¨ã§è¡Œåˆ—æ¼”ç®—ã‚’é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚

### **(1) OpenBLAS ã®å°å…¥**
```bash
sudo apt update
sudo apt install -y libopenblas-dev
```
#### **OpenBLASã‚’Rã®BLASã«è¨­å®š**
```bash
cd /usr/lib/R/lib
sudo mv libRblas.so libRblas.so.bak  # å…ƒã®BLASã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
sudo ln -s /usr/lib/x86_64-linux-gnu/openblas/libopenblas.so libRblas.so
```
BLASã®ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’è¨­å®šï¼š
```bash
export OPENBLAS_NUM_THREADS=4  # 4ã‚¹ãƒ¬ãƒƒãƒ‰ä½¿ç”¨
```
ã¾ãŸã¯ã€Rå†…ã§è¨­å®šï¼š
```r
library(RhpcBLASctl)
blas_set_num_threads(4)  # 4ã‚¹ãƒ¬ãƒƒãƒ‰ã§BLASã‚’ä¸¦åˆ—åŒ–
```

### **(2) Intel MKL ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šé«˜é€Ÿï¼‰**
Intelã® **MKLï¼ˆMath Kernel Libraryï¼‰** ã¯ã€OpenBLASã‚ˆã‚Šé«˜é€Ÿãªã“ã¨ãŒå¤šã„ã§ã™ã€‚

#### **MKL ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```bash
sudo apt install -y intel-mkl
```
#### **MKLã‚’Rã®BLASã«è¨­å®š**
```bash
cd /usr/lib/R/lib
sudo mv libRblas.so libRblas.so.bak
sudo ln -s /opt/intel/mkl/lib/intel64/libmkl_rt.so libRblas.so
```
MKLã®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®šï¼š
```bash
export MKL_NUM_THREADS=4
export OMP_NUM_THREADS=4
```
Rå†…ã§ã®ç¢ºèªï¼š
```r
library(RhpcBLASctl)
blas_get_num_procs()  # ä½¿ç”¨ã•ã‚Œã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’ç¢ºèª
```

---

## **2. OpenMP ã‚’æ´»ç”¨**
BLASã®ä¸¦åˆ—åŒ–ã«åŠ ãˆã€**OpenMP** ã‚’æ´»ç”¨ã™ã‚‹ã¨ã•ã‚‰ãªã‚‹é«˜é€ŸåŒ–ãŒå¯èƒ½ã§ã™ã€‚

ç’°å¢ƒå¤‰æ•°ã§è¨­å®šï¼š
```bash
export OMP_NUM_THREADS=4
```
Rå†…ã§è¨­å®šï¼š
```r
library(RhpcBLASctl)
omp_set_num_threads(4)  # OpenMP ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’4ã«è¨­å®š
```

---


## **3. ä¸¦åˆ—å‡¦ç† (`parallel` ã‚„ `future` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸)**
### **(1) `future` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ä¸¦åˆ—å®Ÿè¡Œ**
```r
install.packages("future.apply")
library(future.apply)

plan(multicore, workers = 4)  # 4ã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å®Ÿè¡Œ
rsvd_result <- future_lapply(1:4, function(x) rsvd(A, k = 10))
```
ã“ã®æ–¹æ³•ã‚’ä½¿ãˆã°ã€è¤‡æ•°ã® `rSVD` è¨ˆç®—ã‚’ä¸¦åˆ—å®Ÿè¡Œã§ãã¾ã™ã€‚



```
library(Matrix)
library(rsvd)
library(RhpcBLASctl)

extSoftVersion()["BLAS"]

blas_set_num_threads(1)
omp_set_num_threads(1)

# see the number of thread
blas_get_num_procs()

gc()
df=fread(file)  # "row,col,value" å½¢å¼
sparse_mat=sparseMatrix(i = df$row, j = df$col, x = df$val)
rm(df)

# è¿‘ä¼¼SVD
system.time({
  svd=rsvd(sparse_mat, k = 20)
})

# ä¸»æˆåˆ†å¾—ç‚¹
pca_scores=svd$u %*% diag(svd$d)
```

```
library(Matrix)
library(rsvd)
library(RhpcBLASctl)

extSoftVersion()["BLAS"]

blas_set_num_threads(4)
omp_set_num_threads(1)

# see the number of thread
blas_get_num_procs()

gc()
df=fread(file)  # "row,col,value" å½¢å¼
sparse_mat=sparseMatrix(i = df$row, j = df$col, x = df$val)
rm(df)

system.time({
  svd=rsvd(sparse_mat, k = 20, q=1)
})
```
